{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pANA_R9Ltba1"
      },
      "source": [
        "### **Note**:\n",
        "\n",
        "Streamlit will cause  \n",
        "\n",
        "\n",
        "```\n",
        "st.session_state has no attribute \"messages\". Did you forget to initialize it?\n",
        "\n",
        "```\n",
        "\n",
        "due to\n",
        "multi-threading bug on notebooks.     \n",
        "Running the code as a script will solve this, the notebook is mainly to explain the code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN211pUZTXI5"
      },
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wc0o5s8xUDe2"
      },
      "outputs": [],
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QVNNhBz8Xjbu"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "# export NVIDIA AI Playground key as NVIDIA_API_KEY!\n",
        "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
        "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
        "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7Jc0DtzVBqe"
      },
      "source": [
        "### Component 1 - Embedding Model and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jmewGzf-U17Q"
      },
      "outputs": [],
      "source": [
        "llm = ChatNVIDIA(model=\"mixtral_8x7b\")\n",
        "document_embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"passage\")\n",
        "query_embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"query\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciC2P_OfY5Lf"
      },
      "source": [
        "### Component 2 - Document Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S2wdU3BmWIB4"
      },
      "outputs": [],
      "source": [
        "st.set_page_config(layout = \"wide\")\n",
        "\n",
        "DOCS_DIR = os.path.abspath(\"./uploaded_docs\")\n",
        "\n",
        "def document_loader(DOCS_DIR):\n",
        "  with st.sidebar:\n",
        "    if not os.path.exists(DOCS_DIR):\n",
        "        os.makedirs(DOCS_DIR)\n",
        "    st.subheader(\"Add to the Knowledge Base\")\n",
        "    with st.form(\"my-form\", clear_on_submit=True):\n",
        "        uploaded_files = st.file_uploader(\"Upload a file to the Knowledge Base:\", accept_multiple_files = True)\n",
        "        submitted = st.form_submit_button(\"Upload!\")\n",
        "\n",
        "    if uploaded_files and submitted:\n",
        "        for uploaded_file in uploaded_files:\n",
        "            st.success(f\"File {uploaded_file.name} uploaded successfully!\")\n",
        "            with open(os.path.join(DOCS_DIR, uploaded_file.name),\"wb\") as f:\n",
        "                f.write(uploaded_file.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vks-MgLb985"
      },
      "source": [
        "### Component 3 - Vector Database Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cXtmB-igb1Pi"
      },
      "outputs": [],
      "source": [
        "with st.sidebar:\n",
        "    # Option for using an existing vector store\n",
        "    use_existing_vector_store = st.radio(\"Use existing vector store if available\", [\"Yes\", \"No\"], horizontal=True)\n",
        "\n",
        "# Path to the vector store file\n",
        "vector_store_path = \"vectorstore.pkl\"\n",
        "\n",
        "# Load raw documents from the directory\n",
        "raw_documents = DirectoryLoader(DOCS_DIR).load()\n",
        "\n",
        "\n",
        "# Check for existing vector store file\n",
        "vector_store_exists = os.path.exists(vector_store_path)\n",
        "vectorstore = None\n",
        "if use_existing_vector_store == \"Yes\" and vector_store_exists:\n",
        "    with open(vector_store_path, \"rb\") as f:\n",
        "        vectorstore = pickle.load(f)\n",
        "    with st.sidebar:\n",
        "        st.success(\"Existing vector store loaded successfully.\")\n",
        "else:\n",
        "    with st.sidebar:\n",
        "        if raw_documents:\n",
        "            with st.spinner(\"Splitting documents into chunks...\"):\n",
        "                text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "                documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "            with st.spinner(\"Adding document chunks to vector database...\"):\n",
        "                vectorstore = FAISS.from_documents(documents, document_embedder)\n",
        "\n",
        "            with st.spinner(\"Saving vector store\"):\n",
        "                with open(vector_store_path, \"wb\") as f:\n",
        "                    pickle.dump(vectorstore, f)\n",
        "            st.success(\"Vector store created and saved.\")\n",
        "        else:\n",
        "            st.warning(\"No documents available to process!\", icon=\"⚠️\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRIuA6I-h149"
      },
      "source": [
        "### Component 4 - LLM Response Generation and Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjOiAEzHhzkI"
      },
      "outputs": [],
      "source": [
        "document_loader(DOCS_DIR)\n",
        "\n",
        "st.subheader(\"Chat with your AI Assistant, Envie!\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"\"\"You are a helpful AI assistant named Envie. You will reply to questions only based on the context that you are provided. \n",
        "      If something is out of context, you will refrain from replying and politely decline to respond to the user.\"\"\"), \n",
        "     (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "user_input = st.chat_input(\"Can you tell me what NVIDIA is known for?\")\n",
        "\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "if user_input and vectorstore!=None:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    docs = retriever.get_relevant_documents(user_input)\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    context = \"\"\n",
        "    for doc in docs:\n",
        "        context += doc.page_content + \"\\n\\n\"\n",
        "\n",
        "    augmented_user_input = \"Context: \" + context + \"\\n\\nQuestion: \" + user_input + \"\\n\"\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        message_placeholder = st.empty()\n",
        "        full_response = \"\"\n",
        "\n",
        "        for response in chain.stream({\"input\": augmented_user_input}):\n",
        "            full_response += response\n",
        "            message_placeholder.markdown(full_response + \"▌\")\n",
        "        message_placeholder.markdown(full_response)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1g1pOePbpaWW"
      },
      "outputs": [],
      "source": [
        "!streamlit run main.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADDi8b86pkad"
      },
      "outputs": [],
      "source": [
        "# expose externally\n",
        "# resources: https://discuss.streamlit.io/t/how-to-launch-streamlit-app-from-google-colab-notebook/42399/2\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYeG6oZDqvS_",
        "outputId": "00c4623b-1428-42f9-9c0f-627ca82beb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.168s\n",
            "your url is: https://shaggy-carpets-know.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht4aEnmtq4PN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
